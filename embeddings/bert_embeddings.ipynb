{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Embeddings\n",
    "This model will embed project descriptions into an embedding.  Creating an embedding for even a small latent space will take 30 minutes for the New York dataset.  This notebook will output the embeddings for each project into a CSV file.\n",
    "\n",
    "The file only needs to be executed if a new embedding is calculated.\n",
    "\n",
    "As a baseline, the smallest BERT model will be used.  This will create a 1D vector of size 512 for every sentence of text provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install keras-bert if necessary\n",
    "\n",
    "# !pip install keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# https://github.com/CyberZHG/keras-bert\n",
    "from keras_bert import extract_embeddings, POOL_NSP, POOL_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_BASE_DIR = os.path.join(os.getcwd(), 'pretrained')\n",
    "os.path.isdir(BERT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Pretrained BERT encoder\n",
    "Many BERT pretrained encoders are available.  The more dimensions that the encoder has, the longer it takes to embed a sentence and the more space that it takes.\n",
    "\n",
    "For purposes of predicting project success, we simply want an encoded space to represent the project description.  We will not be using the embeddings to do any translations or predictions based soley on the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research/bert\n",
    "# levels of 2,4,6,8,10,12\n",
    "# h's of 128,256,512,768\n",
    "# increasing each increases space size and embedding time\n",
    "# uncased_L-2_H-128_A-2     1.77s  512 elements (bert tiny) 64.2 *\n",
    "# uncased_L-12_H-128_A-2    8.92s  1024 elements\n",
    "# uncased_L-4_H-256_A-4     3.4s   2048 elements (bert mini) 65.8\n",
    "# uncased_L-4_H-512_A-8     4.06s  4096 elements  (bert small) 71.2\n",
    "# uncased_L-8_H-512_A-8     7.61s  4096 elements (bert medium) 73.5\n",
    "# uncased_L-12_H-768_A-12   12.9s  6144 elements (bert base)\n",
    "bert_model = 'uncased_L-2_H-128_A-2' \n",
    "model_path = os.path.join(BERT_BASE_DIR, bert_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output file\n",
    "The calculated embeddings will be output to a CSV file that can be read by another process.  Since the time to embed can take an hour, this is the most effective method for sharing the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - path points to file.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../data/Capital_Projects.csv'\n",
    "if os.path.isfile(file_path):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'file_path' and ensure it points to the source file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Porject Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "all_descriptions = data[['PID', 'Description']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indexes of just the first line per project\n",
    "pid_only_index = all_descriptions['PID'].drop_duplicates().index\n",
    "\n",
    "projects = all_descriptions.loc[pid_only_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding CSV File\n",
    "Create a CSV file that includes the PID and embedded description.  In order to ensure that each embedding is the same length, the sentence is embedded rather than each of the words in the sentence.  Each embedding is stored in a format that makes it easy to read when extracting from the saved CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uncased_L-2_H-128_A-2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../data/processed/embeddings_' + bert_model + '.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aae078fdf3a491e80cc010432dbf134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Creating embeddings', max=378.0, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE - This will take 30 minutes to execute\n",
    "# If the file exists, you don't need to run this unless you are changing the model\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    csv_writer.writerow(['PID', 'embedding'])\n",
    "\n",
    "    for row in tqdm(projects.itertuples(), total=len(projects), desc=\"Creating embeddings\"):\n",
    "        \n",
    "        # if project description is nan, make it an underscore\n",
    "        if type(row.Description) == float:\n",
    "            desc = ['_']\n",
    "        else:\n",
    "            # Join all sentences into list of 1 element.\n",
    "            # This ensures that output is same length for each description.\n",
    "            desc = [x.strip() for x in row.Description.split('.') if x != '']\n",
    "            desc = [' '.join(desc)]\n",
    "        \n",
    "        # calculate embedding and format to store in csv file\n",
    "        emb = extract_embeddings(model_path, desc, output_layer_num=4, poolings=[POOL_NSP, POOL_MAX])[0]\n",
    "        emb = str(list(emb)).replace('[','').replace(']','')\n",
    "        \n",
    "        csv_writer.writerow([row.PID, emb])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done Creating Embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Embeddings\n",
    "To read the embeddings, use Pandas to import the file and format the stored embedded values into a list of float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(output_file):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'output_file' and ensure it points to the source file.\")\n",
    "    print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_csv(output_file)\n",
    "\n",
    "def convert(s):\n",
    "    return [float(x) for x in s.embedding.split(',')]\n",
    "\n",
    "embedding['embedding'] = embedding.apply(convert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cosine distance between two similarly described project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
