{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Capital Projects\n",
    "\n",
    "## Notebook 02: Generate Project Description Text BERT Embeddings\n",
    "\n",
    "This notebook will embed each capital project's textual description into an 1-dimensional embedding consisting of 512 embedded values each. A pre-trained [Bidirectional Encoder Representations from Transformers (BERT) network model](https://arxiv.org/abs/1810.04805) is used to generate these project description embeddings.\n",
    "\n",
    "The Python library used to provide the BERT implementation used here is [keras-bert](https://pypi.org/project/keras-bert/). As a baseline, the smallest [available pre-trained BERT model](https://github.com/google-research/bert),  ``uncased_L-2_H-128_A-2``, will be used.  This will create a 1D vector of size 512 for every sentence of text provided.\n",
    "\n",
    "This notebook will output the embeddings for each project into a CSV file.\n",
    "\n",
    "**NOTE:** Depending on the specifications of your hardware, creating an embedding for even a small latent space can take 30 minutes on some machines.\n",
    "\n",
    "### Project authors\n",
    "\n",
    "- [An Hoang](https://github.com/hoangthienan95)\n",
    "- [Mark McDonald](https://github.com/mcdomx)\n",
    "- [Mike Sedelmeyer](https://github.com/sedelmeyer)\n",
    "\n",
    "### Inputs:\n",
    "\n",
    "The following files are required to successfully run this notebook.\n",
    "\n",
    "- ``../data/interim/NYC_capital_projects_all.csv``\n",
    "\n",
    "    A dataframe that provides a snapshot of outcomes, irregardless of available time-interval, for all projects under analysis.\n",
    "\n",
    "### Outputs:\n",
    "\n",
    "The following files are generated by executing the code in this notebook.\n",
    "\n",
    "- ``../data/interim/embeddings_' + bert_model + '.csv``\n",
    "\n",
    "    The resulting BERT embeddings for each capital project's textual description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook contents\n",
    "\n",
    "1. [Imports](#Imports)\n",
    "\n",
    "2. [Read dataset](#Read-dataset)\n",
    "\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from keras_bert import extract_embeddings, POOL_NSP, POOL_MAX\n",
    "# keras_bert info: https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_BASE_DIR = '../models/pretrained_bert'\n",
    "os.path.isdir(BERT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Pretrained BERT encoder\n",
    "Many BERT pretrained encoders are available.  The more dimensions that the encoder has, the longer it takes to embed a sentence and the more space that it takes.\n",
    "\n",
    "For purposes of predicting project success, we simply want an encoded space to represent the project description.  We will not be using the embeddings to do any translations or predictions based soley on the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research/bert\n",
    "# levels of 2,4,6,8,10,12\n",
    "# h's of 128,256,512,768\n",
    "# increasing each increases embedding dimensionality and required processing time\n",
    "# uncased_L-2_H-128_A-2     1.77s  512 elements (bert tiny) 64.2 *\n",
    "# uncased_L-12_H-128_A-2    8.92s  1024 elements\n",
    "# uncased_L-4_H-256_A-4     3.4s   2048 elements (bert mini) 65.8\n",
    "# uncased_L-4_H-512_A-8     4.06s  4096 elements  (bert small) 71.2\n",
    "# uncased_L-8_H-512_A-8     7.61s  4096 elements (bert medium) 73.5\n",
    "# uncased_L-12_H-768_A-12   12.9s  6144 elements (bert base)\n",
    "bert_model = 'uncased_L-2_H-128_A-2' \n",
    "model_path = os.path.join(BERT_BASE_DIR, bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input and output filepaths\n",
    "\n",
    "The calculated embeddings will be output to a CSV file that can be read by another process.  Since the time to embed can take an hour, this is the most effective method for sharing the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - path points to file.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/interim/NYC_capital_projects_all.csv'\n",
    "if os.path.isfile(file_path):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'file_path' and ensure it points to the source file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output filpath: ../data/processed/embeddings_uncased_L-2_H-128_A-2.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = '../data/processed/embeddings_' + bert_model + '.csv'\n",
    "print(\"Output filpath: {}\".format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Project Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "all_descriptions = data[['PID', 'Description']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indexes of just the first line per project\n",
    "pid_only_index = all_descriptions['PID'].drop_duplicates().index\n",
    "\n",
    "projects = all_descriptions.loc[pid_only_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding CSV File\n",
    "Create a CSV file that includes the PID and embedded description.  In order to ensure that each embedding is the same length, the sentence is embedded rather than each of the words in the sentence.  Each embedding is stored in a format that makes it easy to read when extracting from the saved CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55b82a37c324598a53a3f4d4d2539f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Creating embeddings', max=355.0, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8min 22s, sys: 10.4 s, total: 8min 33s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE - This will take 30 minutes to execute\n",
    "# If the file exists, you don't need to run this unless you are changing the model\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    csv_writer.writerow(['PID', 'embedding'])\n",
    "\n",
    "    for row in tqdm(projects.itertuples(), total=len(projects), desc=\"Creating embeddings\"):\n",
    "        \n",
    "        # if project description is nan, make it an underscore\n",
    "        if type(row.Description) == float:\n",
    "            desc = ['_']\n",
    "        else:\n",
    "            # Join all sentences into list of 1 element.\n",
    "            # This ensures that output is same length for each description.\n",
    "            desc = [x.strip() for x in row.Description.split('.') if x != '']\n",
    "            desc = [' '.join(desc)]\n",
    "        \n",
    "        # calculate embedding and format to store in csv file\n",
    "        emb = extract_embeddings(model_path, desc, output_layer_num=4, poolings=[POOL_NSP, POOL_MAX])[0]\n",
    "        emb = str(list(emb)).replace('[','').replace(']','')\n",
    "        \n",
    "        csv_writer.writerow([row.PID, emb])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done Creating Embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Embeddings\n",
    "To read the embeddings, use Pandas to import the file and format the stored embedded values into a list of float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - path points to file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(output_file):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'output_file' and ensure it points to the source file.\")\n",
    "    print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_csv(output_file)\n",
    "\n",
    "def convert(s):\n",
    "    return [float(x) for x in s.embedding.split(',')]\n",
    "\n",
    "embedding['embedding'] = embedding.apply(convert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.13854653, 1.4585932, -6.7886453, 0.0610936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>[-0.13127574, 1.1954153, -6.7207437, 0.0612295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.09863796, 1.6704285, -6.5727553, 0.06882739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[-0.26632923, 1.1822444, -6.7360897, 0.0684237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>[-0.35451388, 1.6325428, -6.692406, 0.10146355...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID                                          embedding\n",
       "0    3  [-0.13854653, 1.4585932, -6.7886453, 0.0610936...\n",
       "1    7  [-0.13127574, 1.1954153, -6.7207437, 0.0612295...\n",
       "2   18  [0.09863796, 1.6704285, -6.5727553, 0.06882739...\n",
       "3   25  [-0.26632923, 1.1822444, -6.7360897, 0.0684237...\n",
       "4   34  [-0.35451388, 1.6325428, -6.692406, 0.10146355..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cosine distance between two similarly described projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
