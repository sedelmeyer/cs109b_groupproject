{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Capital Projects\n",
    "\n",
    "## Notebook 02: Generate Project Description Text BERT Embeddings\n",
    "\n",
    "This notebook will embed each capital project's textual description into an 1-dimensional embedding consisting of 512 embedded values each. A pre-trained [Bidirectional Encoder Representations from Transformers (BERT) network model](https://arxiv.org/abs/1810.04805) is used to generate these project description embeddings.\n",
    "\n",
    "The Python library used to provide the BERT implementation used here is [keras-bert](https://pypi.org/project/keras-bert/). As a baseline, the smallest [available pre-trained BERT model](https://github.com/google-research/bert),  ``uncased_L-2_H-128_A-2``, will be used.  This will create a 1D vector of size 512 for every sentence of text provided.\n",
    "\n",
    "This notebook will output the embeddings for each project into a CSV file.\n",
    "\n",
    "**NOTE:** Depending on the specifications of your hardware, creating an embedding for even a small latent space can take 30 minutes on some machines.\n",
    "\n",
    "### Project authors\n",
    "\n",
    "- [An Hoang](https://github.com/hoangthienan95)\n",
    "- [Mark McDonald](https://github.com/mcdomx)\n",
    "- [Mike Sedelmeyer](https://github.com/sedelmeyer)\n",
    "\n",
    "### Citation:\n",
    "\n",
    "For additional information on the pre-trained BERT model used in this notebook, please see the original project's source repository:\n",
    "\n",
    "- https://github.com/google-research/bert\n",
    "\n",
    "Additionally, this pre-trained model is referenced its authors' in the following article:\n",
    "\n",
    "- Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina. (2019). \"Well-Read Students Learn Better: On the Importance of Pre-training Compact Models\". [arXiv preprint arXiv:1908.08962v2](https://arxiv.org/abs/1908.08962)\n",
    "\n",
    "And, more information regarding BERT itself can be found in the original paper:\n",
    "\n",
    "- Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina. (2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\". [arXiv preprint arXiv:1810.04805](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "### Inputs:\n",
    "\n",
    "The following files are required to successfully run this notebook.\n",
    "\n",
    "- ``../data/interim/NYC_capital_projects_all.csv``\n",
    "\n",
    "    A dataframe that provides a snapshot of outcomes, irregardless of available time-interval, for all projects under analysis.\n",
    "\n",
    "\n",
    "- ``../models/pretrained_bert/uncased_L-2_H-128_A-2/``\n",
    "\n",
    "    A directory containing the pre-trained BERT model, which is accessible on [the Google Research BERT repository](https://github.com/google-research/bert), and downloadable via [the link labeled 2/128 (BERT-Tiny)](https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip).\n",
    "    \n",
    "\n",
    "### Outputs:\n",
    "\n",
    "The following files are generated by executing the code in this notebook.\n",
    "\n",
    "- ``../data/interim/embeddings_uncased_L-2_H-128_A-2.csv``\n",
    "\n",
    "    The resulting BERT embeddings for each capital project's textual description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook contents\n",
    "\n",
    "1. [Imports and set base path](#Imports-and-set-base-path)\n",
    "\n",
    "2. [Select Pretrained BERT encoder](#Select-Pretrained-BERT-encoder)\n",
    "\n",
    "3. [Define input and output filepaths](#Define-input-and-output-filepaths)\n",
    "\n",
    "4. [Read the project descriptions](#Read-the-project-descriptions)\n",
    "\n",
    "5. [Create embedding .csv file](#Create-embedding-.csv-file)\n",
    "\n",
    "6. [Read embeddings to validate the file](#Read-embeddings-to-validate-the-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and set base path\n",
    "\n",
    "[Return to top](#Notebook-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from keras_bert import extract_embeddings, POOL_NSP, POOL_MAX\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_BASE_DIR = '../models/pretrained_bert'\n",
    "os.path.isdir(BERT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select pretrained BERT encoder\n",
    "\n",
    "[Return to top](#Notebook-contents)\n",
    "\n",
    "Many BERT pretrained encoders are available.  The more dimensions that the encoder has, the longer it takes to embed a sentence and the more space that it takes.\n",
    "\n",
    "For purposes of predicting project success, we simply want an encoded space to represent the project description.  We will not be using the embeddings to do any translations or predictions based soley on the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research/bert\n",
    "# levels of 2,4,6,8,10,12\n",
    "# h's of 128,256,512,768\n",
    "# increasing each increases embedding dimensionality and required processing time\n",
    "# uncased_L-2_H-128_A-2     1.77s  512 elements (bert tiny) 64.2 *\n",
    "# uncased_L-12_H-128_A-2    8.92s  1024 elements\n",
    "# uncased_L-4_H-256_A-4     3.4s   2048 elements (bert mini) 65.8\n",
    "# uncased_L-4_H-512_A-8     4.06s  4096 elements  (bert small) 71.2\n",
    "# uncased_L-8_H-512_A-8     7.61s  4096 elements (bert medium) 73.5\n",
    "# uncased_L-12_H-768_A-12   12.9s  6144 elements (bert base)\n",
    "bert_model = 'uncased_L-2_H-128_A-2' \n",
    "model_path = os.path.join(BERT_BASE_DIR, bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input and output filepaths\n",
    "\n",
    "[Return to top](#Notebook-contents)\n",
    "\n",
    "The calculated embeddings will be output to a CSV file that can be read by another process.  Since the time to embed can take an hour, this is the most effective method for sharing the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - path points to file.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/interim/NYC_capital_projects_all.csv'\n",
    "if os.path.isfile(file_path):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'file_path' and ensure it points to the source file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output filpath: ../data/processed/embeddings_uncased_L-2_H-128_A-2.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = '../data/interim/embeddings_' + bert_model + '.csv'\n",
    "print(\"Output filpath: {}\".format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the project descriptions\n",
    "\n",
    "[Return to top](#Notebook-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "all_descriptions = data[['PID', 'Description']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indexes of just the first line per project\n",
    "pid_only_index = all_descriptions['PID'].drop_duplicates().index\n",
    "\n",
    "projects = all_descriptions.loc[pid_only_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding .csv file\n",
    "\n",
    "[Return to top](#Notebook-contents)\n",
    "\n",
    "Create a .csv file that includes the PID and embedded description.  In order to ensure that each embedding is the same length, the sentence is embedded rather than each of the words in the sentence.  Each embedding is stored in a format that makes it easy to read when extracting from the saved .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55b82a37c324598a53a3f4d4d2539f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Creating embeddings', max=355.0, style=ProgressStyle(descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8min 22s, sys: 10.4 s, total: 8min 33s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE - This will take 30 minutes to execute\n",
    "# If the file exists, you don't need to run this unless you are changing the model\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    csv_writer.writerow(['PID', 'embedding'])\n",
    "\n",
    "    for row in tqdm(projects.itertuples(), total=len(projects), desc=\"Creating embeddings\"):\n",
    "        \n",
    "        # if project description is nan, make it an underscore\n",
    "        if type(row.Description) == float:\n",
    "            desc = ['_']\n",
    "        else:\n",
    "            # Join all sentences into list of 1 element.\n",
    "            # This ensures that output is same length for each description.\n",
    "            desc = [x.strip() for x in row.Description.split('.') if x != '']\n",
    "            desc = [' '.join(desc)]\n",
    "        \n",
    "        # calculate embedding and format to store in csv file\n",
    "        emb = extract_embeddings(model_path, desc, output_layer_num=4, poolings=[POOL_NSP, POOL_MAX])[0]\n",
    "        emb = str(list(emb)).replace('[','').replace(']','')\n",
    "        \n",
    "        csv_writer.writerow([row.PID, emb])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done Creating Embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read embeddings to validate the file\n",
    "\n",
    "[Return to top](#Notebook-contents)\n",
    "\n",
    "To read the embeddings, use Pandas to import the file and format the stored embedded values into a list of float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - path points to file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(output_file):\n",
    "    print(\"OK - path points to file.\")\n",
    "else:\n",
    "    print(\"ERROR - check the 'output_file' and ensure it points to the source file.\")\n",
    "    print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_csv(output_file)\n",
    "\n",
    "def convert(s):\n",
    "    return [float(x) for x in s.embedding.split(',')]\n",
    "\n",
    "embedding['embedding'] = embedding.apply(convert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.13854653, 1.4585932, -6.7886453, 0.0610936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>[-0.13127574, 1.1954153, -6.7207437, 0.0612295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.09863796, 1.6704285, -6.5727553, 0.06882739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[-0.26632923, 1.1822444, -6.7360897, 0.0684237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>[-0.35451388, 1.6325428, -6.692406, 0.10146355...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID                                          embedding\n",
       "0    3  [-0.13854653, 1.4585932, -6.7886453, 0.0610936...\n",
       "1    7  [-0.13127574, 1.1954153, -6.7207437, 0.0612295...\n",
       "2   18  [0.09863796, 1.6704285, -6.5727553, 0.06882739...\n",
       "3   25  [-0.26632923, 1.1822444, -6.7360897, 0.0684237...\n",
       "4   34  [-0.35451388, 1.6325428, -6.692406, 0.10146355..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cosine distance between two similarly described projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
